import pandas as pd
from flask import Flask, request, jsonify, render_template, render_template_string
from flask_cors import CORS
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from konlpy.tag import Okt
import requests
import face_recognition # â­ ë”¥ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ (dlib ê¸°ë°˜)
import numpy as np
import base64
import cv2
import os

app = Flask(__name__)
CORS(app)

# ==========================================
# [ì„¤ì •] ì±—ë´‡ ë°ì´í„° ë¡œë“œ (ê¸°ì¡´ ìœ ì§€)
# ==========================================
OLLAMA_MODEL = "gemma3:4b"
SIMILARITY_THRESHOLD = 0.4

try:
    df = pd.read_csv(r"C:\KDT Project\KDT-Project\src\main\java\choi\sdp_back\ai\company_docs.csv")
    df.columns = ['Question', 'Answer']
    print(f"âœ… ì±—ë´‡ ë°ì´í„° {len(df)}ê°œ ë¡œë“œ ì™„ë£Œ")

    okt = Okt()
    tfidf_vectorizer = TfidfVectorizer(tokenizer=okt.morphs)
    tfidf_matrix = tfidf_vectorizer.fit_transform(df['Question'].astype(str))
# ìˆ˜ì • í›„ (ì–´ë–¤ ì—ëŸ¬ì¸ì§€ ì •í™•íˆ ì¶œë ¥í•´ì¤ë‹ˆë‹¤)
except Exception as e:
    print(f"âŒ ì§„ì§œ ì—ëŸ¬ ì›ì¸: {e}")
    df = pd.DataFrame()

# ==========================================
# [ì„¤ì •] ì–¼êµ´ ì¸ì‹ ëª¨ë¸ ë¡œë“œ (ë”¥ëŸ¬ë‹ ë²„ì „) â­
# ==========================================
admin_encoding = None

def load_admin_face():
    global admin_encoding
    image_path = "admin.jpg"

    if not os.path.exists(image_path):
        print("âš ï¸ 'admin.jpg' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. (ë”¥ëŸ¬ë‹ ë²„ì „)")
        return

    try:
        print("ê´€ë¦¬ì ì–¼êµ´(Deep Learning) ë¶„ì„ ì¤‘... (ì‹œê°„ì´ ì¢€ ê±¸ë¦½ë‹ˆë‹¤)")
        # 1. ì´ë¯¸ì§€ ë¡œë“œ
        image = face_recognition.load_image_file(image_path)

        # 2. ì–¼êµ´ íŠ¹ì§• ì¶”ì¶œ (128ê°œ ë²¡í„°)
        encodings = face_recognition.face_encodings(image)

        if len(encodings) > 0:
            admin_encoding = encodings[0]
            print("âœ… ê´€ë¦¬ì ì–¼êµ´ í•™ìŠµ ì™„ë£Œ! (Face Recognition)")
        else:
            print("âŒ ì‚¬ì§„ì—ì„œ ì–¼êµ´ì„ ëª» ì°¾ì•˜ìŠµë‹ˆë‹¤. ë” ì„ ëª…í•œ ì •ë©´ ì‚¬ì§„ì„ ì¨ì£¼ì„¸ìš”.")

    except Exception as e:
        print(f"âŒ ì–¼êµ´ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

load_admin_face()


# ==========================================
# [ê¸°ëŠ¥ 1] ì±—ë´‡ API (ê¸°ì¡´ ìœ ì§€)
# ==========================================
def refine_answer_with_ai(user_query, fact_answer):
    url = "http://localhost:11434/api/generate"
    prompt = f"ì§ˆë¬¸: {user_query}\níŒ©íŠ¸: {fact_answer}\nìœ„ íŒ©íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì¤˜."
    payload = {"model": OLLAMA_MODEL, "prompt": prompt, "stream": False}
    try:
        return requests.post(url, json=payload).json()['response']
    except:
        return fact_answer

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/chat', methods=['POST'])
def chat():
    data = request.json
    user_query = data.get('message', '')
    if df.empty: return jsonify({"response": "ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."})

    user_vec = tfidf_vectorizer.transform([user_query])
    score = cosine_similarity(user_vec, tfidf_matrix).flatten().max()

    if score < SIMILARITY_THRESHOLD:
        return jsonify({"response": "ì£„ì†¡í•©ë‹ˆë‹¤. ì˜ ëª¨ë¥´ëŠ” ë‚´ìš©ì…ë‹ˆë‹¤."})
    else:
        ans = df.loc[cosine_similarity(user_vec, tfidf_matrix).flatten().argmax(), 'Answer']
        return jsonify({"response": refine_answer_with_ai(user_query, ans)})


# ==========================================
# [ê¸°ëŠ¥ 2] ì–¼êµ´ ë¡œê·¸ì¸ API (ë”¥ëŸ¬ë‹ ë²„ì „) â­
# ==========================================

# 1. í…ŒìŠ¤íŠ¸ í˜ì´ì§€
@app.route('/face-test')
def face_test_page():
    return render_template('face_test.html')

# 2. ì–¼êµ´ ê²€ì¦ ë¡œì§
@app.route('/verify-face', methods=['POST'])
def verify_face():
    if admin_encoding is None:
        return jsonify({"status": "error", "msg": "ì„œë²„ì— ê´€ë¦¬ì ì–¼êµ´ì´ ë“±ë¡ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."})

    try:
        # í”„ë¡ íŠ¸ì—ì„œ ë³´ë‚¸ ì´ë¯¸ì§€ ë°›ê¸°
        data = request.json
        image_data = data['image'].split(',')[1]
        image_bytes = base64.b64decode(image_data)

        # OpenCV í¬ë§·ìœ¼ë¡œ ë³€í™˜ (face_recognitionì€ RGBë¥¼ ì”€)
        nparr = np.frombuffer(image_bytes, np.uint8)
        frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) # BGR -> RGB í•„ìˆ˜!

        # 1. ì‚¬ì§„ì—ì„œ ì–¼êµ´ ìœ„ì¹˜ ì°¾ê¸°
        face_locations = face_recognition.face_locations(rgb_frame)
        # ğŸ‘‡ [ìƒˆë¡œ ì¶”ê°€] ì–¼êµ´ì´ ì—†ê±°ë‚˜, 2ëª… ì´ìƒì´ë©´ ê±°ì ˆ!
        if len(face_locations) == 0:
            return jsonify({"status": "fail", "msg": "ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."})

        if len(face_locations) > 1:
            return jsonify({"status": "fail", "msg": "ğŸš« 2ëª… ì´ìƒ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. í˜¼ìë§Œ ë‚˜ì™€ì£¼ì„¸ìš”!"})

        if not face_locations:
            return jsonify({"status": "fail", "msg": "ì–¼êµ´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."})

        # 2. ì–¼êµ´ íŠ¹ì§• ì¶”ì¶œ (ì¸ì½”ë”©)
        unknown_encodings = face_recognition.face_encodings(rgb_frame, face_locations)

        # 3. ë¹„êµ (Compare)
        # tolerance=0.5 (ë‚®ì„ìˆ˜ë¡ ì—„ê²©í•¨. ë³´í†µ 0.4~0.5ê°€ ì ë‹¹)
        for unknown_face in unknown_encodings:
            # ê±°ë¦¬ ê³„ì‚° (0.0 ~ 1.0)
            distance = face_recognition.face_distance([admin_encoding], unknown_face)[0]
            print(f"ì–¼êµ´ ê±°ë¦¬(ì˜¤ì°¨): {distance:.4f}") # ë¡œê·¸ë¡œ í™•ì¸í•´ë³´ê¸°

            # 0.4ë³´ë‹¤ ì‘ìœ¼ë©´ ê°™ì€ ì‚¬ëŒ
            if distance < 0.4:
                return jsonify({"status": "success", "msg": f"ì¸ì¦ ì„±ê³µ! (ì˜¤ì°¨: {distance:.2f})"})

        return jsonify({"status": "fail", "msg": "ë“±ë¡ëœ ê´€ë¦¬ìê°€ ì•„ë‹™ë‹ˆë‹¤."})

    except Exception as e:
        print(e)
        return jsonify({"status": "error", "msg": "ì„œë²„ ì˜¤ë¥˜ ë°œìƒ"})

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5002)